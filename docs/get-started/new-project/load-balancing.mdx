---
id: load-balancing
title: Load balancing use case
sidebar_label: Load balancing
---

![project readme banner](/img/load-balancing.png)

Start a new project using a load balancing use case example.

import CloneRepoGrid from "@site/src/components/CloneRepoGrid/CloneRepoGrid";
import CloneRepoCard from "@site/src/components/CloneRepoCard/CloneRepoCard";

<CloneRepoGrid>
  <CloneRepoCard
    sdk="Python SDK"
    description="Load balancing use case project example"
    link="https://github.com/resonatehq-examples/example-load-balancing-py"
  />
  <CloneRepoCard
    sdk="TypeScript SDK"
    description="Load balancing use case project example"
    link="https://github.com/resonatehq-examples/example-load-balancing-ts"
  />
</CloneRepoGrid>

## Problem

A single worker or microservice instance will eventually become overwhelmed if there is too much work sent its way in a short amount of time.

There are generally two ways to solve for this:

Increase the compute capability for the single worker / microservice.
Increase the number of worker / microservice instances.
There is an upper limit to the first option, and it is a single point of failure if there is only ever one instance running.

Therefore, the second option tends to be the desired approach, because in theory you can scale the number of instances indefinitely. However, this introduces another problem: service discovery and load balancing â€” that is, knowing which worker / application node has the capacity to take more work.

But what happens if a worker/microservice instance crashes after claiming work and beginning to make progress on it?

How does the system detect the failure and know where to recover that work?

These are distributed system engineering issues that developers are commonly forced to solve again and again. Developers are often forced to mix messy service discovery, load balancing, and recovery logic into their application or business logic. This makes for a poor developer experience.

## Solution

Resonate provides built-in service discovery, load balancing, and recovery, all exposed through a simple RPC API and target schema.

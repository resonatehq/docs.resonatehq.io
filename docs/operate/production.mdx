---
id: production
title: Production deployment
sidebar_label: Production deployment
description: Deploy Resonate in production with worker scaling, high availability, and monitoring.
sidebar_position: 9
tags:
  - operate
  - production
  - deployment
  - scaling
---

Production means different things depending on your scale - a small team's production looks different from an enterprise deployment. This guide covers patterns that work today for deploying Resonate reliably at any scale.

## Architecture overview

Resonate's architecture separates coordination from execution:

**Resonate Server** - Coordinates work, stores durable promise state, routes tasks to workers. This is your central coordination point.

**Workers** - Execute your application code. Workers can run anywhere (containers, serverless functions, bare metal) and scale horizontally.

**Key insight:** Workers scale horizontally to handle load. The server coordinates but doesn't execute your functions, so it rarely becomes a bottleneck. This design lets you scale execution capacity independently from coordination.

---

## Worker scaling

Worker scaling is the primary way to handle increased load. Since workers execute your application code, adding more workers directly increases your system's capacity.

### How worker scaling works

Workers register with the server using a **group name**:

```typescript title="Worker registration"
import { Resonate } from "@resonatehq/sdk";

const resonate = Resonate.remote({
  url: "http://resonate-server:8001",
  group: "workers", // All workers in this group can handle the same tasks
});
```

```python title="Worker registration"
from resonate import Resonate

resonate = Resonate.remote(
    url="http://resonate-server:8001",
    group="workers",  # All workers in this group can handle the same tasks
)
```

When you invoke a function targeting a worker group, Resonate automatically distributes work across available workers:

```typescript title="Targeting a worker group"
// This task goes to ANY available worker in the "workers" group
resonate.rpc(
  taskId,
  "processOrder",
  { orderId: "123" },
  resonate.options({
    target: "poll://any@workers",
  })
);
```

### When to scale workers

Scale workers horizontally when you see:

- **High CPU usage** across worker processes (>70% sustained)
- **Task queue buildup** (promises pending longer than expected)
- **Slow response times** for RPC calls
- **Memory pressure** (workers running out of RAM)

You can run as many workers as needed - there's no fixed limit. Start with 2-4 workers and scale based on observed load.

### Worker fault tolerance

If a worker crashes mid-task, Resonate automatically detects the failure (via heartbeat timeout) and reassigns the work to another available worker. The new worker replays the function from the last checkpoint.

This means:
- Worker crashes don't lose in-flight work
- You can safely restart workers for deployments
- Load rebalances automatically when workers go down

### Deployment patterns for workers

**Multiple processes (simple)**

Run multiple worker processes on the same machine or different machines:

```bash title="Start 4 worker processes"
# Terminal 1
node worker.js &
# Terminal 2
node worker.js &
# Terminal 3
node worker.js &
# Terminal 4
node worker.js &
```

**Docker containers**

```yaml title="docker-compose.yml"
version: '3.8'
services:
  resonate-server:
    image: resonatehq/resonate:latest
    ports:
      - "8001:8001"
    environment:
      RESONATE_STORE_POSTGRES_HOST: postgres
      RESONATE_STORE_POSTGRES_DATABASE: resonate
      RESONATE_STORE_POSTGRES_USERNAME: resonate
      RESONATE_STORE_POSTGRES_PASSWORD: secret
    depends_on:
      - postgres

  worker:
    image: your-app:latest
    environment:
      RESONATE_URL: http://resonate-server:8001
    deploy:
      replicas: 5  # Scale to 5 workers
```

**Kubernetes**

```yaml title="worker-deployment.yaml"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: resonate-workers
spec:
  replicas: 10  # Scale to 10 workers
  selector:
    matchLabels:
      app: resonate-worker
  template:
    metadata:
      labels:
        app: resonate-worker
    spec:
      containers:
      - name: worker
        image: your-app:latest
        env:
        - name: RESONATE_URL
          value: "http://resonate-server:8001"
        resources:
          requests:
            cpu: "500m"
            memory: "512Mi"
          limits:
            cpu: "1000m"
            memory: "1Gi"
```

**Serverless workers**

Workers can run as serverless functions (Cloud Run, Lambda, Fargate) that wake up to claim tasks:

```typescript title="Cloud Run worker"
// Worker runs on Cloud Run, polls for tasks
const resonate = Resonate.remote({
  url: process.env.RESONATE_URL,
  group: "cloud-run-workers",
});

// Cloud Run container stays alive polling for work
// Scales to zero when idle, scales up under load
```

:::tip Start with containers, scale to serverless later
Containerized workers are easier to debug and cheaper at low scale. Move to serverless when you need auto-scaling or have highly variable load.
:::

---

## Server reliability

The Resonate server coordinates work but doesn't execute your functions, so its resource requirements are modest compared to workers. A single server can coordinate thousands of workers and millions of promises.

### Persistent storage

**Use PostgreSQL in production.** SQLite is fine for development, but PostgreSQL provides the durability and reliability production systems need.

```bash title="Start server with PostgreSQL"
resonate serve \
  --aio-store-postgres-enable \
  --aio-store-postgres-host localhost \
  --aio-store-postgres-database resonate \
  --aio-store-postgres-username resonate \
  --aio-store-postgres-password secret
```

```yaml title="resonate.yaml"
aio:
  store:
    postgres:
      enable: true
      host: "postgres.example.com"
      database: "resonate"
      username: "resonate"
      password: "secret"
      query: "sslmode=require"
```

### PostgreSQL high availability

Since the server stores all promise state in PostgreSQL, database availability directly impacts system reliability. Use standard PostgreSQL HA patterns:

**Managed services (easiest)**

- AWS RDS with Multi-AZ
- Google Cloud SQL with high availability
- Azure Database for PostgreSQL with zone redundancy
- Supabase with automatic backups

These services handle replication, failover, and backups automatically.

**Self-managed replication**

- Primary-replica setup with automatic failover (using Patroni or similar)
- Streaming replication for read replicas
- Point-in-time recovery (PITR) with WAL archiving

**Backup strategy**

```bash title="Automated PostgreSQL backups"
# Daily full backup
pg_dump -h postgres.example.com -U resonate resonate > backup-$(date +%Y%m%d).sql

# Continuous WAL archiving for PITR
archive_command = 'cp %p /mnt/wal_archive/%f'
```

### Server monitoring

Monitor server health and performance:

**Health check endpoint**

```bash title="Check server health"
curl http://localhost:8001/healthz
```

**Prometheus metrics endpoint**

```bash title="Scrape metrics"
curl http://localhost:9090/metrics
```

Key metrics to watch:
- Promise creation rate
- Promise resolution latency
- Worker heartbeat failures
- Database connection pool usage

### Server restart procedures

The server can be restarted safely without losing work:

1. **Graceful shutdown** - Server stops accepting new work but completes in-flight operations
2. **Workers continue polling** - Workers retry connections during restart
3. **State preserved in PostgreSQL** - All promise state survives restart
4. **Workers resume** - When server comes back, workers reconnect and continue

```bash title="Graceful restart"
# Send SIGTERM for graceful shutdown
kill -TERM $(pgrep resonate)

# Wait for shutdown to complete
sleep 5

# Start server again
resonate serve --config resonate.yaml
```

### When to upgrade server resources

The server's resource needs grow slowly compared to workers. Consider upgrading when:

- **Database connections exhausted** - Increase connection pool size or upgrade server RAM
- **CPU sustained >80%** - Rare, but indicates heavy coordination load
- **Network bandwidth saturated** - Moving large payloads between workers

For most deployments, a modest server (2-4 CPUs, 4-8GB RAM) can coordinate hundreds of workers.

---

## Deployment patterns

### Development and staging

**Docker Compose** for local development and staging environments:

```yaml title="docker-compose.yml (complete stack)"
version: '3.8'

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: resonate
      POSTGRES_USER: resonate
      POSTGRES_PASSWORD: secret
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U resonate"]
      interval: 10s
      timeout: 5s
      retries: 5

  resonate-server:
    image: resonatehq/resonate:latest
    ports:
      - "8001:8001"
      - "9090:9090"
    environment:
      RESONATE_STORE_POSTGRES_ENABLE: "true"
      RESONATE_STORE_POSTGRES_HOST: postgres
      RESONATE_STORE_POSTGRES_DATABASE: resonate
      RESONATE_STORE_POSTGRES_USERNAME: resonate
      RESONATE_STORE_POSTGRES_PASSWORD: secret
    depends_on:
      postgres:
        condition: service_healthy

  worker:
    image: your-app:latest
    environment:
      RESONATE_URL: http://resonate-server:8001
    deploy:
      replicas: 3

volumes:
  postgres-data:
```

### Kubernetes production deployment

**Server deployment** (single replica with persistent storage):

```yaml title="server-deployment.yaml"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: resonate-server
spec:
  replicas: 1  # Single server is sufficient
  selector:
    matchLabels:
      app: resonate-server
  template:
    metadata:
      labels:
        app: resonate-server
    spec:
      containers:
      - name: server
        image: resonatehq/resonate:latest
        ports:
        - containerPort: 8001
          name: http
        - containerPort: 50051
          name: grpc
        - containerPort: 9090
          name: metrics
        env:
        - name: RESONATE_STORE_POSTGRES_ENABLE
          value: "true"
        - name: RESONATE_STORE_POSTGRES_HOST
          value: "postgres-service"
        - name: RESONATE_STORE_POSTGRES_DATABASE
          valueFrom:
            secretKeyRef:
              name: postgres-credentials
              key: database
        - name: RESONATE_STORE_POSTGRES_USERNAME
          valueFrom:
            secretKeyRef:
              name: postgres-credentials
              key: username
        - name: RESONATE_STORE_POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-credentials
              key: password
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8001
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /healthz
            port: 8001
          initialDelaySeconds: 5
          periodSeconds: 5
```

**Worker deployment** (horizontal scaling):

```yaml title="worker-deployment.yaml"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: resonate-workers
spec:
  replicas: 10  # Scale based on load
  selector:
    matchLabels:
      app: resonate-worker
  template:
    metadata:
      labels:
        app: resonate-worker
    spec:
      containers:
      - name: worker
        image: your-app:latest
        env:
        - name: RESONATE_URL
          value: "http://resonate-server:8001"
        - name: WORKER_GROUP
          value: "workers"
        resources:
          requests:
            cpu: "500m"
            memory: "512Mi"
          limits:
            cpu: "1000m"
            memory: "1Gi"
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: resonate-workers-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: resonate-workers
  minReplicas: 5
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

### Serverless workers

**Google Cloud Run worker:**

```dockerfile title="Dockerfile"
FROM node:20-slim
WORKDIR /app
COPY package*.json ./
RUN npm ci --production
COPY . .
CMD ["node", "worker.js"]
```

```bash title="Deploy to Cloud Run"
gcloud run deploy resonate-worker \
  --image gcr.io/your-project/worker:latest \
  --set-env-vars RESONATE_URL=https://resonate.example.com \
  --min-instances 1 \
  --max-instances 100 \
  --cpu 1 \
  --memory 512Mi
```

**AWS Lambda worker:**

Lambda workers can poll for tasks or be triggered by events. Since Lambda has execution time limits, design functions to complete quickly or use step functions for long-running coordination.

:::tip Use containers for long-running workers
Serverless functions (Lambda, Cloud Run) work well for short tasks (under 15 minutes). For longer workflows, use containerized workers that can run indefinitely.
:::

---

## Monitoring and observability

### Metrics

Resonate exposes Prometheus metrics at `http://localhost:9090/metrics`.

**Key metrics to track:**

```promql
# Promise creation rate
rate(resonate_promises_created_total[5m])

# Promise resolution latency
histogram_quantile(0.95, rate(resonate_promise_resolution_duration_seconds_bucket[5m]))

# Worker heartbeat failures (indicates crashed workers)
rate(resonate_worker_heartbeat_failures_total[5m])

# Database connection pool usage
resonate_db_connections_active / resonate_db_connections_max
```

**Prometheus configuration:**

```yaml title="prometheus.yml"
scrape_configs:
  - job_name: 'resonate-server'
    static_configs:
      - targets: ['resonate-server:9090']
    scrape_interval: 15s
```

### Logging

Configure structured logging for production:

```bash title="Set log level"
resonate serve --log-level info
```

Log levels:
- `debug` - Verbose (development only)
- `info` - Standard (production default)
- `warn` - Warnings only
- `error` - Errors only

**Important events to log:**
- Worker registrations/disconnections
- Promise creation/resolution failures
- Database connection issues
- Authentication failures

### Alerting

Set up alerts for critical conditions:

```yaml title="alerting-rules.yml"
groups:
  - name: resonate-alerts
    rules:
      - alert: ResonateServerDown
        expr: up{job="resonate-server"} == 0
        for: 1m
        annotations:
          summary: "Resonate server is down"

      - alert: HighWorkerFailureRate
        expr: rate(resonate_worker_heartbeat_failures_total[5m]) > 5
        for: 5m
        annotations:
          summary: "High worker failure rate"

      - alert: DatabaseConnectionsExhausted
        expr: resonate_db_connections_active / resonate_db_connections_max > 0.9
        for: 5m
        annotations:
          summary: "Database connection pool near capacity"
```

---

## Security in production

For production deployments, always enable authentication. See the [Security guide](/operate/security) for comprehensive coverage.

**Quick checklist:**

- ✅ Enable token-based or basic authentication
- ✅ Use HTTPS/TLS for server API endpoints
- ✅ Secure PostgreSQL connections with SSL
- ✅ Store credentials in secrets (not environment variables)
- ✅ Use firewall rules to restrict server access
- ✅ Run workers in a VPC or private network

```yaml title="Production security config"
api:
  http:
    auth:
      # Token-based auth
      jwt:
        secret: "${JWT_SECRET}"
  grpc:
    tls:
      enabled: true
      cert: "/path/to/cert.pem"
      key: "/path/to/key.pem"

aio:
  store:
    postgres:
      query: "sslmode=require"  # Force SSL for database
```

---

## What's not covered yet

Some features you might expect in a production deployment guide aren't available in Resonate today:

**Multi-server coordination** - The server doesn't currently support horizontal scaling across multiple server instances. A single server is sufficient for most use cases (it coordinates, doesn't execute).

**Server-to-server failover** - There's no built-in automatic failover between multiple server instances. Use PostgreSQL HA/replication for state persistence, and restart the server if it crashes.

**Cross-region disaster recovery** - For multi-region setups, use standard PostgreSQL replication and recovery patterns.

These features aren't implemented yet because **worker horizontal scaling** handles the vast majority of scale needs. The server is a coordination layer, not a computational bottleneck.

If you need more server capacity, upgrade server resources (CPU, RAM) rather than trying to run multiple servers.

:::tip Focus on scaling workers
In nearly all production scenarios, scaling workers horizontally is the right approach. The server coordinates work but doesn't execute it, so it rarely becomes a bottleneck.
:::

---

## Summary

**For production:**
1. Use PostgreSQL for persistent storage (with HA/backups)
2. Scale workers horizontally to handle load (containers or serverless)
3. Monitor server health and metrics
4. Enable authentication and TLS
5. Set up alerts for worker failures and database issues

**The pattern that works:**
- 1 Resonate server (modest resources: 2-4 CPU, 4-8GB RAM)
- 1 PostgreSQL database (managed service or HA replica set)
- N workers (scale based on load: 5-50+ workers common)

Workers scale to meet demand. The server coordinates. PostgreSQL persists state. This architecture is simple, reliable, and scales to handle large workloads.

For more details:
- [Security guide](/operate/security) - Authentication and TLS setup
- [Running the server](/operate/run-server) - Configuration and startup options
- [Example deployments](/learn/deployments) - Real-world deployment tutorials
